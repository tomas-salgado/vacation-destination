{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import ast\n",
    "import nltk\n",
    "from nltk import wordpunct_tokenize\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse.linalg import svds\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct data\n",
    "files = ['api_data_usacomp.csv', 'api_data_5+mil.csv', 'api_data_2_5_mil.csv', 'api_data_1_2_mil.csv',\n",
    "         'api_data_250_500k.csv']#, 'api_data_100_250k.csv']\n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    data = pd.read_csv(file, names=['City', 'Longitude', 'Latitude', 'Ratings', \n",
    "                                         'ObjectNames', 'Description'])\n",
    "    df = pd.concat([df, data], axis=0)\n",
    "\n",
    "df = df[df['Description'] != '[]']\n",
    "df.reset_index(inplace=True)\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', max_df = .7,\n",
    "                            min_df = 1)\n",
    "td_matrix = vectorizer.fit_transform([x for x in df['Description']])\n",
    "td_matrix_np = td_matrix.toarray()\n",
    "td_matrix_np = normalize(td_matrix_np)\n",
    "docs_compressed, s, words_compressed = svds(td_matrix, k=100)\n",
    "words_compressed = words_compressed.transpose()\n",
    "docs_compressed_normed = normalize(docs_compressed)\n",
    "word_to_index = vectorizer.vocabulary_\n",
    "index_to_word = {i:t for t,i in word_to_index.items()}\n",
    "print(docs_compressed.shape,s.shape,words_compressed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver code\n",
    "query = input(\"Type a query: \")\n",
    "query = vectorizer.transform([query]).toarray()\n",
    "query_vec = normalize(np.dot(query, words_compressed)).squeeze()\n",
    "def closest_projects_to_query(query_vec_in, k = 5):\n",
    "    sims = docs_compressed_normed.dot(query_vec_in)\n",
    "    asort = np.argsort(-sims)[:k+1]\n",
    "    return [(i, df['City'][i], sims[i]) for i in asort[1:]]\n",
    "\n",
    "for i, proj, sim in closest_projects_to_query(query_vec):\n",
    "    print(\"{}, {:.4f}\".format(proj, sim))\n",
    "\n",
    "# top_5 = process_query(query, td_mat, city_rev_index, wordpunct_tokenize, ps, stops)\n",
    "# print(\"Your ranked destinations:\")\n",
    "# for i in top_5:\n",
    "#     objects_str = df[df['City'] == i].reset_index()['ObjectNames'][0]\n",
    "#     descr_str = df[df['City'] == i].reset_index()['Description'][0]\n",
    "#     ratings_str = df[df['City'] == i].reset_index()['Ratings'][0]\n",
    "#     objects = ast.literal_eval(objects_str)\n",
    "#     descriptions = ast.literal_eval(descr_str)\n",
    "#     ratings = ast.literal_eval(ratings_str)\n",
    "#     print(i, '- Top Attractions:', objects[np.argmax(ratings)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
