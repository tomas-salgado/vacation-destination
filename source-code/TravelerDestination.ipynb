{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse.linalg import svds\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct data\n",
    "files = ['api_data_usacomp.csv', 'api_data_5+mil.csv', 'api_data_2_5_mil.csv', 'api_data_1_2_mil.csv',\n",
    "         'api_data_250_500k.csv']#, 'api_data_100_250k.csv']\n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    data = pd.read_csv(file, names=['City', 'Longitude', 'Latitude', 'Ratings', \n",
    "                                         'ObjectNames', 'Description'])\n",
    "    df = pd.concat([df, data], axis=0)\n",
    "df = df[df['Description'] != '[]']\n",
    "df.reset_index(inplace=True)\n",
    "p = df['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1685, 100) (100,) (227323, 100)\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity \n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', max_df = .7, min_df = 1)\n",
    "td_matrix = vectorizer.fit_transform([x for x in df['Description']])\n",
    "td_matrix_np = td_matrix.toarray()\n",
    "td_matrix_np = normalize(td_matrix_np)\n",
    "docs_compressed, s, words_compressed = svds(td_matrix, k=100)\n",
    "words_compressed = words_compressed.transpose()\n",
    "docs_compressed_normed = normalize(docs_compressed)\n",
    "word_to_index = vectorizer.vocabulary_\n",
    "index_to_word = {i:t for t,i in word_to_index.items()}\n",
    "print(docs_compressed.shape,s.shape,words_compressed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type a query: pizza\n",
      "Springfield\n",
      "Similarity Score:  0.9445739250274913\n",
      "Popularity Score:  100\n",
      "Top Attractions: \n",
      "['Union Station Square', 'Bust of Abraham Lincoln', 'Illinois State Capitol South Fountain', 'The Colonnade', 'Illinois State Capitol North Fountain']\n",
      "Chicago\n",
      "Similarity Score:  0.9131500417268716\n",
      "Popularity Score:  100\n",
      "Top Attractions: \n",
      "['Man with Fish', 'Pilsen', 'Credit Union 1 Arena', 'Greektown', 'San Marco II']\n",
      "Joliet\n",
      "Similarity Score:  0.9085777433382309\n",
      "Popularity Score:  100\n",
      "Top Attractions: \n",
      "['Gaylord Building', 'Upper Bluff Historic District', 'Brandon Road Dam', 'Rialto Square Theatre', 'Joliet East Side Historic District']\n",
      "Naperville\n",
      "Similarity Score:  0.8830941282059552\n",
      "Popularity Score:  100\n",
      "Top Attractions: \n",
      "['Naper Settlement', 'Museum at Lisle Station Park', 'Naperville Historic District', 'DuPage County Historical Museum', 'Village of Lisle-Benedictine University Sports Complex']\n",
      "Rockford\n",
      "Similarity Score:  0.8262158116762742\n",
      "Popularity Score:  100\n",
      "Top Attractions: \n",
      "['BMO Harris Center', 'Coronado Performing Arts Center', 'Tinker Swiss Cottage & Gardens', 'Beattie Park', 'Haight Village Historic District']\n"
     ]
    }
   ],
   "source": [
    "# driver code\n",
    "query = input(\"Type a query: \")\n",
    "# query = \"beaches\"\n",
    "query = vectorizer.transform([query]).toarray()\n",
    "query_vec = normalize(np.dot(query, words_compressed)).squeeze()\n",
    "def closest_cities_to_query(query_vec_in, k = 5):\n",
    "    sims = docs_compressed_normed.dot(query_vec_in)\n",
    "    asort = np.argsort(-sims)[:k+1]\n",
    "    return [(i, df['City'][i], sims[i]) for i in asort[1:]]\n",
    "\n",
    "for i, city, sim in closest_cities_to_query(query_vec):\n",
    "    if sim != 0:\n",
    "        objects_str = df['ObjectNames'][i]\n",
    "        descr_str = df['Description'][i]\n",
    "        ratings_str = df['Ratings'][i]\n",
    "        objects = ast.literal_eval(objects_str)\n",
    "        descriptions = ast.literal_eval(descr_str)\n",
    "        description_sims = [normalize(np.dot(vectorizer.transform([i]).toarray(), words_compressed)).squeeze() \n",
    "                            for i in descriptions]\n",
    "        description_sims = [i.dot(query_vec) for i in description_sims]\n",
    "        idx = np.argpartition(description_sims, max(-len(description_sims),-5))[-5:]\n",
    "        ratings = ast.literal_eval(ratings_str)\n",
    "        ratings = [int(ratings[i][0]) for i in range(len(ratings))]\n",
    "\n",
    "        top_objects = [objects[i] for i in idx]\n",
    "        top_obj_descriptions = [descriptions[i] for i in idx]\n",
    "        rating_score = int(np.mean(ratings)/3*100)\n",
    "\n",
    "        print(city) \n",
    "        print('Similarity Score: ', sim)\n",
    "        print(\"Popularity Score: \", rating_score)\n",
    "        print('Top Attractions: ')\n",
    "        print(\"{}\".format(top_objects))\n",
    "    else:\n",
    "        print('No Matches Found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
