{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import ast\n",
    "from nltk import wordpunct_tokenize\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse.linalg import svds\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct data\n",
    "files = ['api_data_usacomp.csv', 'api_data_5+mil.csv', 'api_data_2_5_mil.csv', 'api_data_1_2_mil.csv',\n",
    "         'api_data_250_500k.csv']#, 'api_data_100_250k.csv']\n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    data = pd.read_csv(file, names=['City', 'Longitude', 'Latitude', 'Ratings', \n",
    "                                         'ObjectNames', 'Description'])\n",
    "    df = pd.concat([df, data], axis=0)\n",
    "df = df[df['Description'] != '[]']\n",
    "df.reset_index(inplace=True)\n",
    "p = df['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1685, 100) (100,) (227323, 100)\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity \n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', max_df = .7, min_df = 1)\n",
    "td_matrix = vectorizer.fit_transform([x for x in df['Description']])\n",
    "td_matrix_np = td_matrix.toarray()\n",
    "td_matrix_np = normalize(td_matrix_np)\n",
    "docs_compressed, s, words_compressed = svds(td_matrix, k=100)\n",
    "words_compressed = words_compressed.transpose()\n",
    "docs_compressed_normed = normalize(docs_compressed)\n",
    "word_to_index = vectorizer.vocabulary_\n",
    "index_to_word = {i:t for t,i in word_to_index.items()}\n",
    "print(docs_compressed.shape,s.shape,words_compressed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3]\n",
      "Calicut 0.7330,\n",
      " ['EMS Stadium', 'Kozhikode Beach']\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Quilon 0.6660,\n",
      " ['Chinnakada Clock Tower', 'Mahatma Gandhi Park', 'Kollam Beach']\n",
      "[3, 3, 3, 3, 3]\n",
      "Hollywood 0.6468,\n",
      " ['Greynolds Park', 'John U. Lloyd Beach State Park', 'Fulford-by-the-Sea Monument']\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "Miami 0.6406,\n",
      " ['New World Center', 'South Pointe Park', 'South Beach']\n",
      "[3, 3, 3, 3, 3, 3]\n",
      "Huntington Beach 0.6191,\n",
      " ['Bolsa Chica Ecological Reserve', 'Bolsa Chica State Beach', 'Bolsa Chica State Beach']\n"
     ]
    }
   ],
   "source": [
    "# driver code\n",
    "# query = input(\"Type a query: \")\n",
    "query = \"beaches\"\n",
    "query = vectorizer.transform([query]).toarray()\n",
    "query_vec = normalize(np.dot(query, words_compressed)).squeeze()\n",
    "def closest_projects_to_query(query_vec_in, k = 5):\n",
    "    sims = docs_compressed_normed.dot(query_vec_in)\n",
    "    asort = np.argsort(-sims)[:k+1]\n",
    "    return [(i, df['City'][i], sims[i]) for i in asort[1:]]\n",
    "\n",
    "for i, proj, sim in closest_projects_to_query(query_vec):\n",
    "    objects_str = df['ObjectNames'][i]\n",
    "    descr_str = df['Description'][i]\n",
    "    ratings_str = df['Ratings'][i]\n",
    "    objects = ast.literal_eval(objects_str)\n",
    "    descriptions = ast.literal_eval(descr_str)\n",
    "    description_sims = [normalize(np.dot(vectorizer.transform([i]).toarray(), words_compressed)).squeeze() \n",
    "                        for i in descriptions]\n",
    "    description_sims = [i.dot(query_vec) for i in description_sims]\n",
    "    idx = np.argpartition(description_sims, max(-len(description_sims),-3))[-3:]\n",
    "    ratings = ast.literal_eval(ratings_str)\n",
    "    ratings = [int(ratings[i][0]) for i in range(len(ratings))]\n",
    "    print(ratings)\n",
    "    print(\"{} {:.4f},\\n {}\".format(proj, sim, [objects[i] for i in idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
